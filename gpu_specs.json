{
  "_metadata": {
    "description": "GPU TDP specifications for datacenter accelerators",
    "source": "NVIDIA official specifications and datasheets",
    "last_updated": "2025-11",
    "notes": "TDP values represent maximum thermal design power. Actual power consumption varies by workload.",
    "update_instructions": "To add a new GPU, find TDP from manufacturer spec sheets and add entry following the format below."
  },
  "A100": {
    "name": "NVIDIA A100",
    "tdp_watts": 400,
    "vendor": "NVIDIA",
    "memory_gb": 40,
    "notes": "Standard A100 40GB, PCIe or SXM4"
  },
  "A100-80GB": {
    "name": "NVIDIA A100 80GB",
    "tdp_watts": 400,
    "vendor": "NVIDIA",
    "memory_gb": 80,
    "notes": "High memory variant"
  },
  "H100": {
    "name": "NVIDIA H100 PCIe",
    "tdp_watts": 700,
    "vendor": "NVIDIA",
    "memory_gb": 80,
    "notes": "Hopper architecture, PCIe form factor"
  },
  "H100-SXM": {
    "name": "NVIDIA H100 SXM",
    "tdp_watts": 700,
    "vendor": "NVIDIA",
    "memory_gb": 80,
    "notes": "Hopper architecture, SXM5 form factor"
  },
  "V100": {
    "name": "NVIDIA V100",
    "tdp_watts": 300,
    "vendor": "NVIDIA",
    "memory_gb": 32,
    "notes": "Volta architecture, previous generation"
  },
  "T4": {
    "name": "NVIDIA T4",
    "tdp_watts": 70,
    "vendor": "NVIDIA",
    "memory_gb": 16,
    "notes": "Turing architecture, optimized for inference"
  },
  "A10": {
    "name": "NVIDIA A10",
    "tdp_watts": 150,
    "vendor": "NVIDIA",
    "memory_gb": 24,
    "notes": "Ampere architecture, mainstream workloads"
  },
  "A40": {
    "name": "NVIDIA A40",
    "tdp_watts": 300,
    "vendor": "NVIDIA",
    "memory_gb": 48,
    "notes": "Ampere architecture, professional visualization"
  },
  "L4": {
    "name": "NVIDIA L4",
    "tdp_watts": 72,
    "vendor": "NVIDIA",
    "memory_gb": 24,
    "notes": "Ada Lovelace architecture, efficient inference"
  },
  "L40": {
    "name": "NVIDIA L40",
    "tdp_watts": 300,
    "vendor": "NVIDIA",
    "memory_gb": 48,
    "notes": "Ada Lovelace architecture, multi-workload"
  },
  "L40S": {
    "name": "NVIDIA L40S",
    "tdp_watts": 350,
    "vendor": "NVIDIA",
    "memory_gb": 48,
    "notes": "Ada Lovelace architecture, enhanced performance"
  },
  "P100": {
    "name": "NVIDIA P100",
    "tdp_watts": 300,
    "vendor": "NVIDIA",
    "memory_gb": 16,
    "notes": "Pascal architecture, legacy datacenter GPU"
  },
  "K80": {
    "name": "NVIDIA K80",
    "tdp_watts": 300,
    "vendor": "NVIDIA",
    "memory_gb": 24,
    "notes": "Kepler architecture, dual GPU, legacy"
  },
  "MI250X": {
    "name": "AMD Instinct MI250X",
    "tdp_watts": 560,
    "vendor": "AMD",
    "memory_gb": 128,
    "notes": "AMD CDNA2 architecture, HPC and AI"
  },
  "MI210": {
    "name": "AMD Instinct MI210",
    "tdp_watts": 300,
    "vendor": "AMD",
    "memory_gb": 64,
    "notes": "AMD CDNA2 architecture, mainstream datacenter"
  }
}
